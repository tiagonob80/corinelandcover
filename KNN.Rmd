# Classification task

```{r}
# Libraries
library(readr)
library(gridExtra)
library(ggplot2)
library(plotly)
library(tidyr)
library(dplyr)
library(caret)
library(class)
library(knitr)
library(data.table)
set.seed(86)
```

```{r}
train <- read_csv("data/train_data_standardized.csv", show_col_types = FALSE)
validation <- read_csv("data/validation_data_standardized.csv", show_col_types = FALSE)
test <- read_csv("data/test_data_standardized.csv", show_col_types = FALSE)
```

```{r}
# Preprocessing: Drop unnecessary columns
columns_to_remove <- c("longitude", "latitude", "CLC2N", "CLC3N")
train <- train %>% select(-all_of(columns_to_remove))
validation <- validation %>% select(-all_of(columns_to_remove))
test <- test %>% select(-all_of(columns_to_remove))
```

```{r}
data <- as.data.frame(data)
train <- as.data.frame(train)
test <- as.data.frame(test)
```

# Classification

## Balancing the dataset (only train data)

```{r}
# Change this to use or not balancing
BALANCE = TRUE
```

```{r}
# Step 1: Identify class distribution
class_distribution <- table(train$CLC1N)
print("Original class distribution:")
print(class_distribution)
print("Original class distribution (%):")
print(class_distribution/sum(class_distribution)*100)
```

```{r}
# Step 2: Define target proportions

CLASS_1_PROPORTION = 0.2
CLASS_2_PROPORTION = 0.3
CLASS_3_PROPORTION = 0.3
CLASS_4_PROPORTION = 0.1
CLASS_5_PROPORTION = 0.1
target_proportions <- c(CLASS_1_PROPORTION, CLASS_2_PROPORTION, CLASS_3_PROPORTION, CLASS_4_PROPORTION, CLASS_5_PROPORTION)
total_samples <- sum(class_distribution)
target_distribution <- floor(total_samples * target_proportions)
print("Target class distribution:")
print(target_distribution)
print("Target class distribution (%):")
print(target_distribution/sum(target_distribution)*100)
```

```{r}
# Step 3: Perform balancing
if (BALANCE){
  balanced_train_cl1 <- data.frame()
  for (class in names(class_distribution)) {
    class_data <- train[train$CLC1N == class, ]
    target_size <- target_distribution[as.numeric(class)]
    
    if (nrow(class_data) > target_size) {
      # Undersample majority class
      sampled_data <- class_data[sample(1:nrow(class_data), target_size), ]
    } else {
      # Oversample minority classes
      sampled_data <- class_data
      remaining_size <- target_size - nrow(sampled_data)
      additional_data <- class_data[sample(1:nrow(class_data), size = remaining_size, replace = TRUE), ]
      sampled_data <- rbind(sampled_data, additional_data)
    }
    
    balanced_train_cl1 <- rbind(balanced_train_cl1, sampled_data)
  }
  train <- balanced_train_cl1
}

# Check new distribution
print("Balanced class distribution:")
print(table(train$CLC1N))
```

```{r}
X_train <- train[, -c(ncol(train))]
y_train <- train[[ncol(train)]]
y_train <- factor(y_train)
is.factor(y_train)

X_test <- test[, -c(ncol(test))]
y_test <- test[[ncol(test)]]
y_test <- factor(y_test)
is.factor(y_test)
```

## KNN

### Model

```{r}
#Parameter Tuning for KNN
tune_grid <- expand.grid(k = seq(1, 20, by = 2))
knn_tune <- train(
  x = X_train, y = y_train,
  method = "knn",
  tuneGrid = tune_grid,
  trControl = trainControl(method = "cv", number = 5)
)

```

```{r}
best_k <- knn_tune$bestTune$k
print(paste("Optimal k:", best_k))
```

#### Confusion Matrices

```{r}
# Generate predictions for train and test sets
knn_predictions_train <- knn(train = X_train, test = X_train, cl = y_train, k = 17)
knn_predictions_test <- knn(train = X_train, test = X_test, cl = y_train, k = 17)

# Confusion Matrices
knn_predictions_train_confusion_matrix <- confusionMatrix(data = knn_predictions_train, reference = y_train)
knn_predictions_test_confusion_matrix <- confusionMatrix(data = knn_predictions_test, reference = y_test)


```

```{r}
# Display accuracy for train and test sets
cat("Accuracy train: ", knn_predictions_train_confusion_matrix$overall["Accuracy"], "\n")
cat("Accuracy test: ", knn_predictions_test_confusion_matrix$overall["Accuracy"], "\n")

```

```{r}
# Train Confusion Matrix Plot
train_plot <- ggplot(data = as.data.frame(knn_predictions_train_confusion_matrix$table), 
                     aes(x = Prediction, y = Reference)) +
    geom_tile(aes(fill = Freq), color = "white") +
    scale_fill_gradient(low = "red", high = "yellow") +
    geom_text(aes(label = Freq), vjust = 1, size = 5) +  
    labs(title = "Confusion Matrix - Train", x = "Predicted", y = "Real") +
    theme_minimal() +
    theme(
        plot.title = element_text(size = 20),  
        axis.title.x = element_text(size = 15),  
        axis.title.y = element_text(size = 15),  
        axis.text.x = element_text(size = 12),  
        axis.text.y = element_text(size = 12)   
    )

ggplotly(train_plot)

# Test Confusion Matrix Plot
test_plot <- ggplot(data = as.data.frame(knn_predictions_test_confusion_matrix$table), 
                    aes(x = Prediction, y = Reference)) +
    geom_tile(aes(fill = Freq), color = "white") +
    scale_fill_gradient(low = "red", high = "yellow") +
    geom_text(aes(label = Freq), vjust = 1, size = 5) +  
    labs(title = "Confusion Matrix - Test", x = "Predicted", y = "Real") +
    theme_minimal() +
    theme(
        plot.title = element_text(size = 20),  
        axis.title.x = element_text(size = 15),  
        axis.title.y = element_text(size = 15),  
        axis.text.x = element_text(size = 12),  
        axis.text.y = element_text(size = 12)   
    )

ggplotly(test_plot)

```

```{r}
# ----------- TRAIN ----------------

# Extract class-wise metrics
class_metrics_train <- as.data.frame(knn_predictions_train_confusion_matrix$byClass)
class_metrics_train$Class <- rownames(class_metrics_train)

# Extract overall metrics
overall_metrics_train <- data.frame(
  Metric = names(knn_predictions_train_confusion_matrix$overall),
  Value = knn_predictions_train_confusion_matrix$overall
)

# Class-wise metrics table
kable(
  class_metrics_train, 
  format = "html", 
  digits = 3, 
  caption = "Class-wise Metrics for Train Data"
)

# Overall metrics table
kable(
  overall_metrics_train, 
  format = "html", 
  digits = 3, 
  caption = "Overall Metrics for Train Data"
)

# ----------- TEST ----------------

# Extract class-wise metrics
class_metrics_test <- as.data.frame(knn_predictions_test_confusion_matrix$byClass)
class_metrics_test$Class <- rownames(class_metrics_test)

# Extract overall metrics
overall_metrics_test <- data.frame(
  Metric = names(knn_predictions_test_confusion_matrix$overall),
  Value = knn_predictions_test_confusion_matrix$overall
)

# Class-wise metrics table
kable(
  class_metrics_test, 
  format = "html", 
  digits = 3, 
  caption = "Class-wise Metrics for Test Data"
)

# Overall metrics table
kable(
  overall_metrics_test, 
  format = "html", 
  digits = 3, 
  caption = "Overall Metrics for Test Data"
)

```

#### Accuracy Plot

```{r}
# Visualization: Accuracy by k
accuracy_plot <- ggplot(knn_tune$results, aes(x = k, y = Accuracy)) +
  geom_line() +
  geom_point() +
  labs(title = "Accuracy by k", x = "Number of Neighbors (k)", y = "Accuracy") +
  theme_minimal()

print(accuracy_plot)
```

```{r}

```
